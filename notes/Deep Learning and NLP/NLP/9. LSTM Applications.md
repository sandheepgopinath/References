#### Process
First step is to encode the word/sentence/document as a vector
Multiple methods can be used for this
- One Hot Encoding will create a very sparse vector
- Word2vec will create even more dense vectors
- Hugging face models can help
	- BertTokenizer
	- BertModel
	- MBert
	- Roberta etc




#### Sentiment analysis
- The sentence can be encoded as vectors by using different approaches mentioned above
- Problems would be 
	- Handling of out of vocabulary words
	- Capturing context of the sentences
	- Byte Pair encoding is an approach used in this case
	- ![[Pasted image 20220402200547.png]]
- Architecture
 	 ![[Pasted image 20220402201123.png]]
	 ![[Pasted image 20220402215545.png]]

	- < SEP  > ,< END>, < CLS> etc are used to mark sentence separations, end and beginning
	
#### Sentence Generation
![[Pasted image 20220402215839.png]]
	- Outputs from CNN are passed on to LSTMS which generates sentences accordingly. 
	- The LSTMS are trained on such datasets so that it can generate words in the right sequences and the CNN serves as the input so as to decide which words should be used. 
	- Pre-trained LSTM's can be used to reduce training time. This helps in generating the words sequentially. 
	
#### Machine translation
 ![[Pasted image 20220402220229.png]]
 ![[Pasted image 20220403012551.png]]
	- LSTM will wait until it find a <END> and will start producing words

	
	