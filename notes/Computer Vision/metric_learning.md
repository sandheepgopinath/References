# Metric Learning and Siamese Network

- Traditional Image processing methods needs large number of images
- orFr face recognition, if we use a taditional classification using CNN the image will have to be trained with large number of samples. And it required retrainining with large samples to effectively detect the person
- Periodic retraining is costly


##### One Shot Learning 
![](https://miro.medium.com/max/960/1*g-561DsAfbU6gcVEk9AC4g.jpeg)
- The idea begind this architecture is to use a reference image and find the similarity with the image to be tested
- Siamese network helps in finding the similarity

## Concept of Metric Learning
Metric is like a distance. 
Properties of distances
- Always positive
- Follows triangle inequality. 
![](https://www.onlinemathlearning.com/image-files/triangle-inequality.png)
- Inverse of similarity. Smaller the distance, larger the similarity
Symetric : distance between a-b = distance between b-a
- Metric learning is the task of leanring a distance function over objects

Eg : Eucledian distance, Mahnattan distance etv

## Siamese network
![](https://miro.medium.com/max/1400/1*LwOBbwGXMZUy6OzkFAPTzw.png)

- Reference image is converted into embedding.
- So is the test image
- The embedding can be generated by any networks like Lenet, AlexNet etc
- The embeddings are then compared to see how similar the two metrics are

<b> Loss function</b>
- If the the reference and test images are the same, then the distance between the embeddings should be the minimized
	-min( dist( d1, d2) )
- If the reference and test images are different, then the distance between the embeddings should be maximized. 
	- max ( margin, margin-dist(d1, d2))
- Idea behind contrastive loss function
	- Contrastive loss requires a pair of positive and negative training data. The positive pair contains an anchor sample and a positive sample, and a negative pair contains an anchor sample and a negative sample.
    - The Contrastive loss function's objective is to have a small distance for positive pairs and a greater distance for negative pairs.
    ![](https://miro.medium.com/max/620/1*T3Sa6guHEwlWQ9DU0qASTw.png)
    ![](https://miro.medium.com/max/647/1*ySkiKhIZ5F-4UEohucoPCQ.png)
    
## Triplet Learning
![](https://omoindrot.github.io/assets/triplet_loss/triplet_loss.png)
![](https://miro.medium.com/max/1400/1*EgT2EhqKW5hVrNYX6Y-rKg.png)
- f(x) takes x as an input and returns a 128-dimensional vector w.
- i denotes iâ€™th input.
- Subscript a indicates Anchor image, p indicates Positive image, n indicates Negative image.

Objective is to minimize the above equation which means
- Minimizing the first term
- Maximizing the second term
- Third term is bias which acts as threshold


## Distance measurements can be 
- L1 Norm ( Manhattan Dist)
- L2 Norm ( Eucledian distance )


## Similarity measurements
- Dot product
- Arc Cosine
- Radial Basic Function ( RBF )
- 